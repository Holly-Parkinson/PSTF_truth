{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb80ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================#\n",
    "#  Import Packages   #\n",
    "#====================#\n",
    "\n",
    "import math \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from scipy.stats import beta\n",
    "\n",
    "import uproot3 as uproot\n",
    "\n",
    "# BDT\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, recall_score, precision_score, average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from matplotlib.pylab import rcParams\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from iminuit import Minuit\n",
    "import ROOT\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f5fbe1",
   "metadata": {},
   "source": [
    "## First to read in the flat caf files and the trees, mainly the genie truth and the rec trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c927b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================#\n",
    "#  A function for creating dataframes and importing data #\n",
    "#  from root files                                       #\n",
    "#========================================================#\n",
    "def new_df(file):\n",
    "    \n",
    "    \n",
    "    #———————————————————————————————————————————————————————————————————#\n",
    "    # First, define variables needed from the genie truth and rec trees #\n",
    "    #———————————————————————————————————————————————————————————————————#\n",
    "\n",
    "    genieEvtRec_vars = [\"GenieEvtRec.StdHepPdg\", \n",
    "                        \"GenieEvtRec.StdHepX4\", \n",
    "                        \"GenieEvtRec.StdHepP4\",\n",
    "                        \"GenieEvtRec.EvtVtx\"]\n",
    "\n",
    "    rec_vars = [\"rec.slc.truth.iscc\",\n",
    "                \"rec.mc.nu.iscc\"]\n",
    "    \n",
    "    #————————————————————————————————————\n",
    "    # import the trees from the root file\n",
    "    #————————————————————————————————————\n",
    "    \n",
    "    T_rec = uproot.open(file)['recTree']\n",
    "    T_genieEvtRec = uproot.open(file)['GenieEvtRecTree']\n",
    "\n",
    "    #—————————————————————————————————————\n",
    "    # for each tree, create a data frame\n",
    "    #—————————————————————————————————————\n",
    "    \n",
    "    \n",
    "    #Reco dfs\n",
    "    df_genieEvtRec = T_genieEvtRec.pandas.df(genieEvtRec_vars, flatten=False)\n",
    "    df_rec = T_rec.pandas.df(rec_vars, flatten=False)\n",
    "    \n",
    "    #use concat to merge the individual reco dataframes\n",
    "    df_ = pd.concat([df_genieEvtRec, df_rec], axis=1)\n",
    "\n",
    "    # Add additional variables\n",
    "    # ------------------------------------------------\n",
    "    # CHANGE HERE TO ADD NEW VARIABLES TO DATAFRAME\n",
    "    # ------------------------------------------------  \n",
    "    df_ = calc_costheta_beam_dir(df_)\n",
    "    df_ = calc_costheta_target(df_)\n",
    "    df_ = GenieEvtRec_neutrino_pdg_var(df_)\n",
    "    df_ = add_GenieEvtRec_iscc_var(df_)\n",
    "\n",
    "    return df_\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda93a1f",
   "metadata": {},
   "source": [
    "### Functions for adding extra vars into the dataframe\n",
    "\n",
    "#### - Create Genie-Truth isCC var\n",
    "#### - Creating Genie-Truth neutrino PDG var\n",
    "#### - selection of primary muon and get their momentum separately from GenieTruth P4 var\n",
    "#### - Lepton angle with neutrino direction estimated as the projection from the BNB target\n",
    "#### - Lepton angle with neutrino direction estimated as the unit vector (0,0,1) in the beam direction (z)\n",
    "#### -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8fd4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_GenieEvtRec_iscc_var(df):\n",
    "    \"\"\"\n",
    "    Adds a scalar CC flag (0 or 1) from rec.mc.nu.iscc,\n",
    "    which is stored as a 1-element array per event.\n",
    "    Returns the full dataframe with the new column added.\n",
    "    \"\"\"\n",
    "\n",
    "    df_ = df.copy()\n",
    "\n",
    "    # Flatten rec.mc.nu.iscc (looks like [1], [0], ...)\n",
    "    df_[\"GenieEvtRec_iscc\"] = df_[\"rec.mc.nu.iscc\"].str[0]\n",
    "\n",
    "    return df_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe02a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenieEvtRec_neutrino_pdg_var(df):\n",
    "    \"\"\"\n",
    "    Create a new variable for the Genie-Truth neutrino PDG from the StdHepPdg array\n",
    "    \"\"\"\n",
    "    df_ = df.copy()\n",
    "    \n",
    "    df_[\"GenieEvtRec_nuPdg\"] = df_[\"GenieEvtRec.StdHepPdg\"].str[0]\n",
    "    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad408f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_primary_muon_first_from_row(row,\n",
    "                                    pdg_col=\"GenieEvtRec.StdHepPdg\",\n",
    "                                    p4_col=\"GenieEvtRec.StdHepP4\"):\n",
    "    \"\"\"\n",
    "    Primary muon = first PDG with abs(pdg) == 13.\n",
    "    Returns a Series (px, py, pz) or (nan, nan, nan) if no muon.\n",
    "    \"\"\"\n",
    "    pdg_list = row[pdg_col]\n",
    "    p4_list  = row[p4_col]\n",
    "\n",
    "    # guard against missing data\n",
    "    if pdg_list is None or p4_list is None:\n",
    "        return pd.Series([np.nan, np.nan, np.nan],\n",
    "                         index=[\"GenieEvtRec_mu_px\", \"GenieEvtRec_mu_py\", \"GenieEvtRec_mu_pz\"])\n",
    "\n",
    "    for i, pdg in enumerate(pdg_list):\n",
    "        if abs(pdg) == 13:\n",
    "            px, py, pz, E = p4_list[i]\n",
    "            return pd.Series([px, py, pz],\n",
    "                             index=[\"GenieEvtRec_mu_px\", \"GenieEvtRec_mu_py\", \"GenieEvtRec_mu_pz\"])\n",
    "\n",
    "    # no muon found in this event\n",
    "    return pd.Series([np.nan, np.nan, np.nan],\n",
    "                     index=[\"GenieEvtRec_mu_px\", \"GenieEvtRec_mu_py\", \"GenieEvtRec_mu_pz\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acec4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================================================================#\n",
    "# Angle between target→vertex direction and primary muon (GENIE truth muon) #\n",
    "#===========================================================================#\n",
    "\n",
    "def calc_costheta_target(df):\n",
    "    #-----------------------------\n",
    "    # 1) Primary muon px, py, pz\n",
    "    #-----------------------------\n",
    "    df[[\"GenieEvtRec_mu_px\", \"GenieEvtRec_mu_py\", \"GenieEvtRec_mu_pz\"]] = df.apply(\n",
    "        get_primary_muon_first_from_row, axis=1\n",
    "    )\n",
    "\n",
    "    #-----------------------------\n",
    "    # 2) Vector from TARGET -> VERTEX\n",
    "    #    target at (-74, 0, -110)\n",
    "    #-----------------------------\n",
    "    x_targ, y_targ, z_targ = -74.0, 0.0, -110.0\n",
    "\n",
    "    # Get the vector components of the vtx position\n",
    "    df.loc[:,'GenieEvtRec_nuvtxX'] = df[\"GenieEvtRec.EvtVtx[0]\"]\n",
    "    df.loc[:,'GenieEvtRec_nuvtxY'] = df[\"GenieEvtRec.EvtVtx[1]\"]\n",
    "    df.loc[:,'GenieEvtRec_nuvtxZ'] = df[\"GenieEvtRec.EvtVtx[2]\"]\n",
    "\n",
    "\n",
    "    df.eval(\n",
    "        f\"vec_targ_vtx_X = GenieEvtRec_nuvtxX - ({x_targ})\",\n",
    "        inplace=True\n",
    "    )\n",
    "    df.eval(\n",
    "        f\"vec_targ_vtx_Y = GenieEvtRec_nuvtxY - ({y_targ})\",\n",
    "        inplace=True\n",
    "    )\n",
    "    df.eval(\n",
    "        f\"vec_targ_vtx_Z = GenieEvtRec_nuvtxZ - ({z_targ})\",\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    #-----------------------------\n",
    "    # 3) Norms of the two vectors\n",
    "    #-----------------------------\n",
    "    df.eval(\n",
    "        \"norm_vec_targ_vtx = sqrt(vec_targ_vtx_X**2 + vec_targ_vtx_Y**2 + vec_targ_vtx_Z**2)\",\n",
    "        inplace=True\n",
    "    )\n",
    "    df.eval(\n",
    "        \"norm_vec_mu = sqrt(GenieEvtRec_mu_px**2 + GenieEvtRec_mu_py**2 + GenieEvtRec_mu_pz**2)\",\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    #-----------------------------\n",
    "    # 4) cos(theta) between them\n",
    "    #   cosθ = (a·b) / (|a||b|)\n",
    "    #-----------------------------\n",
    "    df.eval(\n",
    "        \"cos_theta_bnb_target = (vec_targ_vtx_X * GenieEvtRec_mu_px\"\n",
    "        \"           + vec_targ_vtx_Y * GenieEvtRec_mu_py\"\n",
    "        \"           + vec_targ_vtx_Z * GenieEvtRec_mu_pz)\"\n",
    "        \"          / (norm_vec_targ_vtx * norm_vec_mu)\",\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    # avoid 0/0\n",
    "    mask_zero = (df[\"norm_vec_targ_vtx\"] == 0) | (df[\"norm_vec_mu\"] == 0)\n",
    "    df.loc[mask_zero, \"cos_theta_bnb_target\"] = np.nan\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcc0894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================================#\n",
    "# A Function for calculating the angle b/w beam direction axis and muon from vertex #\n",
    "#===================================================================================#\n",
    "\n",
    "def calc_costheta_beam_dir(df):\n",
    "    \n",
    "    # extract primary muon px, py, pz\n",
    "    df[[\"GenieEvtRec_mu_px\", \"GenieEvtRec_mu_py\", \"GenieEvtRec_mu_pz\"]] = df.apply(\n",
    "        get_primary_muon_first_from_row, axis=1\n",
    "    )\n",
    "    \n",
    "    # calculate the norm of the vector\n",
    "    df.eval('GenieEvtRec_mu_pmag = sqrt(GenieEvtRec_mu_px**2 + GenieEvtRec_mu_py**2 + GenieEvtRec_mu_pz**2)', inplace=True)\n",
    "    \n",
    "    # beam is along +z → cosθ = pz / |p|\n",
    "    df.eval(\n",
    "        'cos_theta_beam_dir = GenieEvtRec_mu_pz / GenieEvtRec_mu_pmag',\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    # avoid invalid 0/0\n",
    "    df.loc[df[\"GenieEvtRec_mu_pmag\"] == 0, \"cos_theta_beam_dir\"] = np.nan\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acbc34f",
   "metadata": {},
   "source": [
    "### Functions for plotting\n",
    "\n",
    "#### - MC category definition, including background\n",
    "#### - Plotting function for stacked NON-area normalized distributions\n",
    "#### - Functions to confirm the cuts and the vars applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecd5d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def isNue_NuebarCC(df):\n",
    "#     df_ = df[((df.GenieEvtRec_nuPdg==12) | (df.GenieEvtRec_nuPdg==-12))    \n",
    "#              & (df[\"rec.mc.nu.iscc\"] == 1)]\n",
    "#     return df_\n",
    "\n",
    "# def isNumuCC(df):\n",
    "#     df_ = df[(df.GenieEvtRec_nuPdg==14) &                             \n",
    "#              (df[\"rec.mc.nu.iscc\"] == 1)]\n",
    "#     return df_\n",
    "\n",
    "# def isNumu_barCC(df):\n",
    "#     df_ = df[(df.GenieEvtRec_nuPdg==-14) &                             \n",
    "#              (df[\"rec.mc.nu.iscc\"] == 1)]\n",
    "#     return df_\n",
    "\n",
    "# def isNCpi(df):\n",
    "#     # charged pion (±211) in final state\n",
    "#     mask_pi = np.array([\n",
    "#         211 in arr for arr in np.abs(np.array(df[\"GenieEvtRec.StdHepPdg\"]))\n",
    "#     ])\n",
    "#     # NC = isCC == 0\n",
    "#     mask_isNC = df[\"rec.mc.nu.iscc\"] == 0\n",
    "#     df_ = df[mask_isNC & mask_pi]\n",
    "#     return df_\n",
    "\n",
    "# def isNC(df):\n",
    "#     # no charged pion\n",
    "#     mask_no_pi = np.array([\n",
    "#         211 not in arr for arr in np.abs(np.array(df[\"GenieEvtRec.StdHepPdg\"]))\n",
    "#     ])\n",
    "#     # NC = isCC == 0\n",
    "#     mask_isNC = df[\"rec.mc.nu.iscc\"] == 0\n",
    "#     df_ = df[mask_isNC & mask_no_pi]\n",
    "#     return df_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd9255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNumuCC(df):\n",
    "    mask = (df[\"GenieEvtRec_nuPdg\"] == 14) & (df[\"GenieEvtRec_iscc\"] == 1)\n",
    "    return df[mask]\n",
    "\n",
    "def isNumu_barCC(df):\n",
    "    mask = (df[\"GenieEvtRec_nuPdg\"] == -14) & (df[\"GenieEvtRec_iscc\"] == 1)\n",
    "    return df[mask]\n",
    "\n",
    "def isNue_NuebarCC(df):\n",
    "    mask_flavour = (df[\"GenieEvtRec_nuPdg\"] == 12) | (df[\"GenieEvtRec_nuPdg\"] == -12)\n",
    "    mask_cc      = (df[\"GenieEvtRec_iscc\"] == 1)\n",
    "    return df[mask_flavour & mask_cc]\n",
    "\n",
    "def isNCpi(df):\n",
    "    # NC with at least one charged pion (±211)\n",
    "    mask_isNC = (df[\"GenieEvtRec_iscc\"] == 0)\n",
    "    mask_pi = df[\"GenieEvtRec.StdHepPdg\"].apply(\n",
    "        lambda lst: any(abs(p) == 211 for p in lst)\n",
    "    ).to_numpy()\n",
    "    return df[mask_isNC & mask_pi]\n",
    "\n",
    "def isNC(df):\n",
    "    # NC with NO charged pion (±211)\n",
    "    mask_isNC = (df[\"GenieEvtRec_iscc\"] == 0)\n",
    "    mask_no_pi = df[\"GenieEvtRec.StdHepPdg\"].apply(\n",
    "        lambda lst: not any(abs(p) == 211 for p in lst)\n",
    "    ).to_numpy()\n",
    "    return df[mask_isNC & mask_no_pi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a355c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================#\n",
    "#  Functions setting vars to plot after cuts  #\n",
    "#=============================================#\n",
    "\n",
    "def plots_for_SelectionCuts(df_, label, condition='default'):\n",
    "    \n",
    "    # this function makes all the plots that you want to plot throughout the pre-selection cuts\n",
    "    \n",
    "    if (condition=='default'):\n",
    "        # --- MC/DATA comparison\n",
    "        # x-dir reco neutrino vertex (also plot zoomed in edges)\n",
    "        mc_data_stacked_hist(df_, \"GenieEvtRec.EvtVtx[0]\", \\\n",
    "                            \"plots/%s_nuvtxX\" % label, \"True neutrino Vertex X [cm]\", \\\n",
    "                            -200., 200, 25)\n",
    "        \n",
    "        # y-dir reco neutrino vertex (also plot zoomed in edges)\n",
    "        mc_data_stacked_hist(df_, \"GenieEvtRec.EvtVtx[1]\", \\\n",
    "                            \"plots/%s_nuvtxY\" % label, \"True neutrino Vertex Y [cm]\", \\\n",
    "                            -200, 200, 25)\n",
    "        # z-dir reco neutrino vertex (also plot zoomed in edges)\n",
    "        mc_data_stacked_hist(df_, \"GenieEvtRec.EvtVtx[2]\", \\\n",
    "                            \"plots/%s_nuvtxZ\" % label, \"True neutrino Vertex Z [cm]\", \\\n",
    "                            0, 500, 25)\n",
    "\n",
    "\n",
    "        # Flash Time (temporarily used as 1 bin histo)\n",
    "        mc_data_stacked_hist(df_, \"GenieEvtRec.EvtVtx[1]\",\\\n",
    "                            \"plots/%s_1_bin_histogram\" % label, \"1-Bin (A.U.)\", \\\n",
    "                            -1000, 1000, 1)\n",
    "\n",
    "        # # 1 bin histo with no category, data vs rest\n",
    "        # mc_data_stacked_hist_no_cat(df_, \"GenieEvtRec.EvtVtx[1]\", \\\n",
    "        #                     \"plots/%s_1\" % label, \"1-Bin (A.U.)\", \\\n",
    "        #                     1000, 1000, 1)\n",
    "\n",
    "    \n",
    "        # calculated theta angle b/w beam and muon\n",
    "        mc_data_stacked_hist(df_, \"cos_theta_bnb_target\",\\\n",
    "                            \"plots/%s_cos_theta\" % label, r\"cos($\\theta$) w.r.t the Projected BNB target\",\\\n",
    "                            -1.2, 1.2, 25)\n",
    "        \n",
    "        mc_data_stacked_hist(df_, \"cos_theta_beam_dir\",\\\n",
    "                            \"plots/%s_cos_theta\" % label, r\"cos($\\theta$) w.r.t the Beam Direction\",\\\n",
    "                            -1.2, 1.2, 25)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================#\n",
    "#  A Function for Plotting Stacked Histograms #\n",
    "#=============================================#\n",
    "\n",
    "\n",
    "def mc_data_stacked_hist(df_, var, plot_png_name, xaxis, xmin, \\\n",
    "                         xmax, nbins):\n",
    "    #————————————————————————————————————————————————#\n",
    "    # Restrict the range of df in the plotting range #\n",
    "    #————————————————————————————————————————————————#\n",
    "    \n",
    "    \n",
    "    # df_data = df_data[(df_data[var]>=xmin) & (df_data[var]<=xmax)]\n",
    "    # df_ext = df_ext[(df_ext[var]>=xmin) & (df_ext[var]<=xmax)]\n",
    "    # df_mc = df_mc[(df_mc[var]>=xmin) & (df_mc[var]<=xmax)]\n",
    "    # df_dirt = df_dirt[(df_dirt[var]>=xmin) & (df_dirt[var]<=xmax)]\n",
    "    \n",
    "   \n",
    "    \n",
    "    #————————————————————————————————————————————#\n",
    "    # Get the number of entries for each dataset #\n",
    "    #————————————————————————————————————————————#\n",
    "    \n",
    "    n_mc = len(df_)\n",
    "\n",
    "    #———————————————————————————————————#\n",
    "    # Classify mc df into each topology #\n",
    "    #———————————————————————————————————#\n",
    "    \n",
    "    # numuCC\n",
    "    df_numuCC = isNumuCC(df_)\n",
    "    n_numuCC = len(df_numuCC)\n",
    "\n",
    "    # numubarCC\n",
    "    df_numu_barCC = isNumu_barCC(df_)\n",
    "    n_numu_barCC = len(df_numu_barCC)\n",
    "\n",
    "    # NCpi+,-\n",
    "    df_ncpi = isNCpi(df_)\n",
    "    n_ncpi = len(df_ncpi)\n",
    "\n",
    "    # NC\n",
    "    df_nc = isNC(df_)\n",
    "    n_nc = len(df_nc)\n",
    "    \n",
    "    # nue and nuebarCC\n",
    "    df_nue_nuebarCC = isNue_NuebarCC(df_)\n",
    "    n_nue_nuebarCC = len(df_nue_nuebarCC)\n",
    "\n",
    "    print('\\nOverlay (%i entries)' % n_mc)\n",
    "    print('NumuCC %10i' % n_numuCC)\n",
    "    print('NumubarCC    %10i' % n_numu_barCC)\n",
    "    print('NCpi      %10i' % n_ncpi)\n",
    "    print('NC        %10i' % n_nc)\n",
    "    print('Nue/NuebarCC %10i' % n_nue_nuebarCC)\n",
    "    print('Total     %10i' % (n_numuCC + n_numu_barCC \\\n",
    "                              + n_ncpi + n_nc + n_nue_nuebarCC))\n",
    "\n",
    "\n",
    "    #—————————————#\n",
    "    # get entries #\n",
    "    #—————————————#\n",
    "    \n",
    "    hist_list = [df_numuCC[var],\n",
    "                df_numu_barCC[var],\n",
    "                df_nc[var],\n",
    "                df_ncpi[var],\n",
    "                df_nue_nuebarCC[var]]\n",
    "\n",
    "\n",
    "    # #—————————————#\n",
    "    # # get weight  #\n",
    "    # #—————————————#\n",
    "    \n",
    "    # w_list = [df_cosmic[weight],\n",
    "    #             df_outFV[weight],\n",
    "    #             df_numuCC[weight],\n",
    "    #             df_numu_barCC[weight],\n",
    "    #             df_nc[weight],\n",
    "    #             df_ncpi[weight],\n",
    "    #             df_nue_nuebarCC[weight],\n",
    "    #             df_ext[weight],\n",
    "    #             df_dirt[weight]]\n",
    "\n",
    "\n",
    "    #—————————————#\n",
    "    # Colors!!!!! #\n",
    "    #—————————————#\n",
    "    \n",
    "    c_list = ['paleturquoise',\n",
    "            'red',\n",
    "            'limegreen',\n",
    "            'aqua',\n",
    "            'orange']\n",
    "    #         'saddlebrown',\n",
    "    #         'grey',\n",
    "    #         'gold',\n",
    "    #         'pink']\n",
    "\n",
    "    # c_data = 'black'\n",
    "    \n",
    "    \n",
    "    #————————#\n",
    "    # labels #\n",
    "    #————————#\n",
    " \n",
    "    label_list = [r'$\\nu_{\\mu}$ CC (%1.1f)'%(n_numuCC),\n",
    "                r'$\\bar{\\nu}_{\\mu}$ CC (%1.1f)'%(n_numu_barCC),\n",
    "                'NC (%1.1f)'%(n_nc),\n",
    "                r'NC $\\pi$ (%1.1f)'%(n_ncpi),\n",
    "                r'$\\nu_{e}$ CC (%1.1f)'%(n_nue_nuebarCC)]\n",
    "    \n",
    "    #————————————————————————————#\n",
    "    # Calculate Stat Uncertainty #\n",
    "    #————————————————————————————#\n",
    "\n",
    "    h_numuCC, b_numuCC = np.histogram(hist_list[0], bins=nbins, range=(xmin,xmax))\n",
    "    h_numuBarCC, b_numuBarCC = np.histogram(hist_list[1], bins=nbins, range=(xmin,xmax))\n",
    "    h_nc, b_nc = np.histogram(hist_list[2], bins=nbins, range=(xmin,xmax))\n",
    "    h_ncPi, b_ncPi = np.histogram(hist_list[3], bins=nbins, range=(xmin,xmax))\n",
    "    h_nueCC, b_nueCC = np.histogram(hist_list[4], bins=nbins, range=(xmin,xmax))\n",
    "\n",
    "    # sum mc distributions\n",
    "    total_mc = np.array([h_numuCC, h_numuBarCC, h_nc, h_ncPi, h_nueCC])\n",
    "    total_mc = total_mc.sum(axis=0)\n",
    "    total_mc_max = np.max(total_mc)\n",
    "\n",
    "    # calculate their individual stat uncert as sqrt(number of entries) \n",
    "    stat_numuCC = np.sqrt(h_numuCC)\n",
    "    stat_numuBarCC = np.sqrt(h_numuBarCC)\n",
    "    stat_nc = np.sqrt(h_nc)\n",
    "    stat_ncPi = np.sqrt(h_ncPi)\n",
    "    stat_nueCC = np.sqrt(h_nueCC)\n",
    "\n",
    "    total_stat = np.array([stat_numuCC, stat_numuBarCC, \n",
    "                        stat_nc, stat_ncPi,  stat_nueCC])\n",
    "    total_stat = np.sqrt(total_stat.sum(axis=0))\n",
    "\n",
    "\n",
    "    #——————————————————————#\n",
    "    # Create Stacked Histo #\n",
    "    #——————————————————————#\n",
    "    # #xerr for uneven histo reco nu E\n",
    "    # if (not isinstance(nbins, int)):\n",
    "    #     xerr_reco_nuE = []\n",
    "    #     for i in range(len(nbins)):\n",
    "    #         print(len(nbins), i)\n",
    "    #         if (i<len(nbins)-1):\n",
    "    #             xerr_reco_nuE.append(0.5*(nbins[i+1]-nbins[i]))              \n",
    "    \n",
    "    fig, axs = plt.subplots(1, 1, figsize=(8,8))\n",
    "    plt.subplots_adjust(left=0.125, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.1)\n",
    "    axs.hist(hist_list, bins=nbins, range=(xmin,xmax), color=c_list, label=label_list, stacked=True)\n",
    "    h_mc_max = np.max(total_mc_max)\n",
    "    # err_bar = [np.sqrt(x) for x in h_data] # h_err = sqrt(bin)\n",
    "    # mid = 0.5*(b_data[1:] + b_data[:-1])\n",
    "    # if (not isinstance(nbins, int)):\n",
    "    #     axs[0].errorbar(mid, h_data, xerr=xerr_reco_nuE, yerr=err_bar, color='black', label=label_data, fmt='o')\n",
    "    # else:\n",
    "    #     axs[0].errorbar(mid, h_data, xerr=0.5*(xmax-xmin)/nbins, yerr=err_bar, color='black', label=label_data, fmt='o')\n",
    "    # upvals = np.append((np.array(total_mc)+np.array(total_stat)),(np.array(total_mc)+np.array(total_stat))[-1])\n",
    "    # lowvals = np.append((np.array(total_mc)-np.array(total_stat)),(np.array(total_mc)-np.array(total_stat))[-1])\n",
    "    # axs[0].fill_between(b_data, lowvals, upvals, step='post', color='gray', hatch='///', alpha=0.3, zorder=2)\n",
    "    axs.legend(ncol=2, fontsize=12, frameon=False, loc='best')\n",
    "    axs.set_ylabel('Entries', size=15)\n",
    "    axs.set_xlabel('%s' % xaxis, size=15)\n",
    "    axs.set_ylim([0, 1.5*h_mc_max])\n",
    "  \n",
    "    plt.savefig('%s.png' % plot_png_name, dpi=600)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa96fe",
   "metadata": {},
   "source": [
    "## MAIN ANALYSIS CODE\n",
    "### - Create the dataframe(s)\n",
    "### - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1cd8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================#\n",
    "# Relevant files and paths   #\n",
    "#============================#\n",
    "\n",
    "file_RHC_BNB = \"/Users/s2106059/Documents/sbnd/PSTF_truth/samples/prodgenie_v10_06_01_g4bnb_rhc_v2_1.flat.caf.root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e725bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RHC_BNB = new_df(file_RHC_BNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb675535",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RHC_BNB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2779a13d",
   "metadata": {},
   "source": [
    "### Cutflow\n",
    "\n",
    "#### - No cut, truth neutrino interactions\n",
    "#### - Charge Current selection\n",
    "#### - Vertex Containment, fiducial volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7637e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_for_SelectionCuts(df_RHC_BNB, 'RHC_BNB_all')\n",
    "#df_RHC_BNB.to_hdf('dfs/df_RHC_BNB_no_selection.hdf5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0d378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========================#\n",
    "# Charge Current Selection #\n",
    "#==========================#\n",
    "\n",
    "df_RHC_BNB_CCSelection = df_RHC_BNB[(df_RHC_BNB['GenieEvtRec_iscc'] == 1)]\n",
    "plots_for_SelectionCuts(df_RHC_BNB_CCSelection, 'RHC_BNB_CCSelection')\n",
    "#df_RHC_BNB_CCSelection.to_hdf('dfs/df_RHC_BNB_CCSelection.hdf5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c276c00",
   "metadata": {},
   "source": [
    "# BDT Stage\n",
    "\n",
    "From the previous last selection, that's the sample that'll be used for BDT training. Due to truth study, there will be a binary BDT to separate between $\\nu_\\mu CC$ and $\\bar{\\nu}_\\mu CC$. The only background will be the negligible mixed $\\nu_e$ and $\\bar{\\nu}_e CC$ events\n",
    "\n",
    "- Auxiliary functions used for BDT, mainly for labeling signals and creating BDT labels\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8170e289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================#\n",
    "# Auxiliary functions used for BDT #\n",
    "#==================================#\n",
    "\n",
    "\n",
    "def label_signal(df_):\n",
    "    # this function labels the sample, =1 for signal (numuCC events), and =0 for background (otherwise) # flip definition\n",
    "      \n",
    "    condition_numubar = (df_['truth_nuPdg']==-14)\n",
    "    condition_numu = (df_['truth_nuPdg']==14)\n",
    "    condition_cc = (df_['truth_isCC']==1)\n",
    "\n",
    "    condition_not_numubar = (df_['truth_nuPdg']!=-14)\n",
    "    condition_not_numu = (df_['truth_nuPdg']!=14)\n",
    "    condition_not_cc = (df_['truth_isCC']!=1)\n",
    "\n",
    "    condition_not_allNumu_reco = (df_['numu_cc_flag']<1)\n",
    "    \n",
    "    query_numubarcc = condition_numubar & condition_cc\n",
    "    query_numucc = condition_numu & condition_cc\n",
    "    query_others = (condition_not_numubar | condition_not_numu) & condition_not_cc\n",
    "\n",
    "    df_numucc_init = df_[(query_numucc)]\n",
    "    df_numubarcc_init = df_[(query_numubarcc)]\n",
    "    df_others_init = df_.drop(df_numucc_init.index, errors='ignore').drop(df_numubarcc_init.index, errors='ignore')\n",
    "    totalEvents = len(df_numucc_init) + len(df_numubarcc_init) + len(df_others_init)\n",
    "    \n",
    "    df_[\"bdt_numubarcc_label\"] = df_.apply(lambda row:1 if query_numubarcc[row.name] else 0, axis=1)\n",
    "    df_[\"bdt_numucc_label\"] = df_.apply(lambda row:1 if query_numucc[row.name] else 0, axis=1)\n",
    "    df_[\"bdt_others_label\"] = df_.apply(lambda row:1 if query_others[row.name] else 0, axis=1)\n",
    "\n",
    "    #Calculate the percentage of 1's\n",
    "    percentage_signal_numu = (len(df_numucc_init) / totalEvents) * 100\n",
    "    print(f\"Labelled dataset. Portion of signal numuCC events in this sample: {percentage_signal_numu:.2f}%\")\n",
    "    \n",
    "    percentage_signal_numubar = (len(df_numubarcc_init) / totalEvents) * 100\n",
    "    print(f\"Labelled dataset. Portion of signal numubarCC events in this sample: {percentage_signal_numubar:.2f}%\")\n",
    "\n",
    "    percentage_others = (len(df_others_init) / totalEvents) * 100\n",
    "    print(f\"Labelled dataset. Portion of background events in this sample: {percentage_others:.2f}%\")\n",
    "    \n",
    "def remove_background_events(df_):\n",
    "    # remove any event that is not nueCC/nuebarCC\n",
    "    query = \"(truth_nuPdg==14 | truth_nuPdg==-14) & truth_isCC==1\"\n",
    "    num_events_before = len(df_)\n",
    "    df_.query(query, inplace=True) # keep only events where query=True\n",
    "    contaminant_contribution = (num_events_before - len(df_))/num_events_before\n",
    "    print(f\"Removed {num_events_before - len(df_)} contaminants from the selection sample. This\"\n",
    "          f\" constitutes {contaminant_contribution:.2%} of the sample.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c45f92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numu_xsec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
